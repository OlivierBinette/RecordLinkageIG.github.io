[
  {
    "path": "posts/2021-12-23-record-linkage-at-the-gpsg-community-pantry/",
    "title": "Record Linkage at the GPSG Community Pantry",
    "description": "Description of the record linkage system used at the GPSG Community Pantry",
    "author": [
      {
        "name": "Olivier Binette",
        "url": "https://olivierbinette.github.io"
      }
    ],
    "date": "2021-12-23",
    "categories": [
      "Python",
      "Record Linkage"
    ],
    "contents": "\n\nContents\nIntroduction\nFood Insecurity on Campus\n\nThe Record Linkage Approach\nDeterministic Record Linkage Rule\nImplementation\n\nModel Evaluation\nFinal thoughts\n\nNote: this post is under construction.\nIntroduction\nDuke’s Graduate and Professional Student Government (GPSG) has been operating a community food pantry for about five years. The pantry provides non-perishable food and basic need items to graduate and professional students on campus. There is a weekly bag program, where students order customized bags of food to be picked up on Saturdays, as well as an in-person shopping program open on Thursdays and Saturdays.\n\nThe weekly bag program, which began in March 2020 and is still the most popular pantry offering, provides quite a bit of data regarding pantry customers and their habits. Some customers have ordered more than 80 times in the past 2 years, while others only ordered once or twice. For every order, we have the customer’s first name and last initial, an email address, a phone number in a few cases, an address in some cases (for delivery), we have demographic information some cases, and we have the food order information. Available quasi-identifying information is shown in Table 1 below.\nTable 1: Quasi-identifying information provided on Qualtrics bag order order forms. Note that phone number and address were only required while delivery was offered. Furthermore, most customers stop answering demographic questions after a few orders.\nQuestion no.\nQuestion\nAnswer form\nMandatory?\n-\nIP address\n-\nYes\n2\nFirst name and last initial\nFree form\nYes\n3\nDuke email\nFree form\nYes\n4\nPhone number\nFree form\nNo\n6\nAddress\nFree form\nNo\n8\nFood allergies\nFree form\nNo\n9\nNumber of members in household\n1-2 or 3+\nYes\n10\nWant baby bag?\nYes or no\nYes\n30\nDegree\nMultiple choices or Other\nNo\n31\nSchool\nMultiple choices or Other\nNo\n32\nYear in graduate school\nMultiple choices\nNo\n33\nNumber of adults in household\nMultiple choices\nNo\n34\nNumber of children in household\nMultiple choices\nNo\nGaining the most insight from this data requires linking order records made by the same customer. Identifying individual customers and associating them with an order history allows us to investigate shopping recurrence patterns and identify potential issues with the pantry’s offering. For instance, we can know who stopped ordering from the pantry after the home delivery program ended. These are people who, most likely, do not have a car to get to the pantry but might benefit from new programs, such as a rideshare program or a gift card program.\nThis blog post describes the way in which records are linked at the Community Pantry. As we will see, the record linkage problem is not particularly difficult. It is not trivial either, however, and it does require care to ensure that it runs reliably and efficiently, and that it is intelligible and properly validated. This post goes in detail into these two aspects of the problem.\nRegarding efficiency and reliability of the software system, I describe the development of a Python module, called GroupByRule, for record linkage at the pantry. This Python module is maintainable, documented and tested, ensuring reliability of the system and the potential for its continued use throughout the years, even as technical volunteers change at the pantry. Regarding validation of the record linkage system, I describe simple steps that can be taken to evaluate model performance. This model evaluation procedure uses probabilistic record linkage and clerical review to validate to validate the simpler deterministic approach.\nBefore jumping into the technical part, let’s take a step back to discuss the issue of food insecurity on campus.\nFood Insecurity on Campus\nIt is often surprising to people that some Duke students might struggle having access to food. After all, Duke is one of the richest campus in the US with its 12 billion endowment. Prior to the covid-19 pandemic, this wealth could be seen on campus and benefit many. Every weekday, there were several conferences and events with free food. Me and many other graduate students would participate in these events, earning 3-4 free lunches every week. Free food on campus is now a thing of the past, for the most part.\nHowever, free lunch or not, it’s important to realize the many financial challenges which students can face. International students on F-1 and J-1 visas have limited employment opportunities in the US. Many graduate students are married, have children or have other dependents which may not be eligible to work in the US either. Even if they are lucky enough to be paid a 9 or 12 months stipend, this stipend doesn’t go very far. For other students, going to Duke means living on a mixture of loans, financial aid, financial support from parents, and side jobs. Any imbalance in this rigid system can leave students having to compromise between their education and their health.\nA 2019 study from the World Food Policy Center reported that about 19% of graduate and professional students at Duke experienced food insecurity in the past year. This means they were unable to afford a balanced and sufficient diet, they were afraid of not having enough money for food, or they skipped meals and went hungry due to lack of money. The GPSG Community Pantry has recently been leading efforts to expand food insecurity monitoring on campus – we are hoping to have more data in 2022 and in following years.\nThe Record Linkage Approach\nThe bag order forms contains email addresses which are highly reliable for linkage. If two records have the same email, we know for certain that they are from the same customer. However, customers do not always enter the same email address when submitting orders. Despite the resquest to use a Duke email address, some customers use personal emails. Furthermore, Duke email addresses have two forms. For instance, my duke email is both ob37@duke.edu and olivier.binette@duke.edu. Emails are therefore not sufficient for linkage. Phone numbers can be used as well, but these are only available for the period when home delivery was available.\nFirst name and last initial can be used to supplement emails and phone numbers. Again, agreement on first name and last initial provides strong evidence for match. On the other hand, people do not always enter their names in the same way.\nCombining the use of emails, phone numbers, and names, we may therefore link records which agree on any one of these attributes. This is a simple deterministic record linkage approach which should be reliable enough for the data analysis use of the pantry.\nDeterministic Record Linkage Rule\nTo be more precise, record linkage proceeds as follows:\nRecords are processed to clean and standardize the email, phone and name attributes. That is, leading and trailing whitespace are removed, capitalization is standardized, phone numbers are validated and standardized, and punctuation is removed from names.\nRecords which agree on any of their email, phone or name attributes are linked together.\nConnected components of the resulting graph are computed in order to obtain record clusters.\nThis record linkage procedure is extremely simple. It relies the fact that all three attributes are reliable indicators of a match and that, for two matching records, it is likely that at least one of these three attributes will be in agreement.\nAlso, the simplicity of the approach allows the use of available additional information (such as IP address and additional questions) for model validation. If the use of this additional information does not highlight any flaws with the simple deterministic approach, then this means that the deterministic approach is already good enough. We will come back to this when discussing model validation techniques.\nImplementation\nOur deterministic record linkage system is implemented in Python with some generality. The goal is for the system to be able to adapt to changes in data or processes.\nThe fundamental component of the system is a LinkageRule class. LinkageRule objects can be fitted to data, providing either a clustering or a linkage graph. For instance, a LinkageRule might be a rule to link all records which agree on the email attribute. Another LinkageRule might summarize a set of other rules, such as taking the union or intersection of their links.\nThe interface is as follows:\n\nfrom abc import ABC, abstractmethod\n\n\nclass LinkageRule(ABC):\n    \"\"\"\n    Interface for a linkage rule which can be fitted to data.\n\n    This abstract class specifies three methods. The `fit()` method fits the \n    linkage rule to a pandas DataFrame. The `graph` property can be used after \n    `fit()` to obtain a graph representing the linkage fitted to data.  The \n    `groups` property can be used after `fit()` to obtain a membership vector \n    representing the clustering fitted to data.\n    \"\"\"\n    @abstractmethod\n    def fit(self, df):\n        pass\n\n    @property\n    @abstractmethod\n    def graph(self):\n        pass\n\n    @property\n    @abstractmethod\n    def groups(self):\n        pass\n\nNote that group membership vectors, our representation for cluster groups, are meant to be a numpy integer array with entries indicating what group (cluster) a given record belongs to. Such a “groups” vector should not contain NA values; rather it should contain distinct integers for records that are not in the same cluster.\nWe will now define two other classes, Match and Any, which allow us to implement deterministic record linkage. The Match class implements an exact matching rule, while Any is the logical disjunction of a given set of rules. Our deterministic record linkage rule for the pantry will therefore be defined as follows:\n\nrule = Any(Match(\"name\"), Match(\"email\"), Match(\"phone\"))\n\nFollowing the LinkageRule interface, this rule will then be fitted to the data and used as follows:\n\nrule.fit(data)\ndata.groupby(rule.groups).last() # Get last visit data for all customers.\n\nThe benefit of this general interface is that it is extendable. By default, the Any class will return connected components when requesting group clusters. However, other clustering approaches could be used. Exact matching rules could also be relaxed to fuzzy matching rules based on string distance metrics or probabilistic record linkage. All of this can be implemented as additional LinkageRule subclasses in a way which is compatible with the above.\nLet’s now work on the Match class. For efficiency, we’ll want Match to operate at the groups level. That is, if Match is called on a set of rules, then we’ll first compute groups for these rules, before computing the intersection of these groups. This core functionality is implemented in the function groups_from_rules() below. The function groups() is a simple wrapper to interpret strings as a matching rule on the corresponding column.\n\nimport pandas as pd\nimport numpy as np\nimport itertools\nfrom igraph import Graph\n\ndef _groups(rule, df):\n    \"\"\"\n    Fit linkage rule to dataframe and return membership vector.\n\n    Parameters\n    ----------\n    rule: string or LinkageRule\n        Linkage rule to be fitted to the data. If `rule` is a string, then this \n        is interpreted as an exact matching rule for the corresponding column.\n    df: DataFrame\n        pandas Dataframe to which the rule is fitted.\n\n    Returns\n    -------\n    Membership vector (i.e. integer vector) u such that u[i] indicates the \n    cluster to which dataframe row i belongs. \n\n    Notes\n    -----\n    NA values are considered to be non-matching.\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> df = pd.DataFrame({\"fname\":[\"Olivier\", \"Jean-Francois\", \"Alex\"], \n      \"lname\":[\"Binette\", \"Binette\", pd.NA]})\n\n    Groups specified by distinct first names:\n    >>> _groups(\"fname\", df)\n    array([2, 1, 0], dtype=int8)\n\n    Groups specified by same last names:\n    >>> _groups(\"lname\", df)\n    array([0, 0, 3], dtype=int8)\n\n    Groups specified by a given linkage rule:\n    >>> rule = Match(\"fname\")\n    >>> _groups(rule, df)\n    array([2, 1, 0])\n    \"\"\"\n    if (isinstance(rule, str)):\n        arr = np.copy(pd.Categorical(df[rule]).codes)\n        I = (arr == -1)  # NA value indicators\n        arr[I] = np.arange(len(arr), len(arr)+sum(I))\n        return arr\n    elif isinstance(rule, LinkageRule):\n        return rule.fit(df).groups\n    else:\n        raise NotImplementedError()\n\n\ndef _groups_from_rules(rules, df):\n    \"\"\"\n    Fit linkage rules to data and return groups corresponding to their logical \n    conjunction.\n\n    This function computes the logical conjunction of a set of rules, operating \n    at the groups level. That is, rules are fitted to the data, membership \n    vector are obtained, and then the groups specified by these membership \n    vectors are intersected.\n\n    Parameters\n    ----------\n    rules: list[LinkageRule]\n        List of strings or Linkage rule objects to be fitted to the data. \n        Strings are interpreted as exact matching rules on the corresponding \n        columns.\n\n    df: DataFrame\n        pandas DataFrame to which the rules are fitted.\n\n    Returns\n    -------\n    Membership vector representing the cluster to which each dataframe row \n    belongs.\n\n    Notes\n    -----\n    NA values are considered to be non-matching.\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> df = pd.DataFrame({\"fname\":[\"Olivier\", \"Jean-Francois\", \"Alex\"], \n      \"lname\":[\"Binette\", \"Binette\", pd.NA]})\n    >>> _groups_from_rules([\"fname\", \"lname\"], df)\n    array([2, 1, 0])\n    \"\"\"\n\n    arr = np.array([_groups(rule, df) for rule in rules]).T\n    groups = np.unique(arr, axis=0, return_inverse=True)[1]\n    return groups\n\nWe can now implement Match as follows. Note that the Graph representation of the clustering is only computed if and when needed.\n\nclass Match(LinkageRule):\n    \"\"\"\n    Class representing an exact matching rule over a given set of columns.\n\n    Attributes\n    ----------\n    graph: igraph.Graph\n        Graph representing linkage fitted to the data. Defaults to None and is \n        instanciated after the `fit()` function is called.\n\n    groups: integer array\n        Membership vector for the linkage clusters fitted to the data. Defaults \n        to None and is instanciated after the `fit()` function is called.\n\n    Methods\n    -------\n    fit(df)\n        Fits linkage rule to the given dataframe.\n\n    Examples\n    --------\n    >>> import pandas as pd\n    >>> df = pd.DataFrame({\"fname\":[\"Olivier\", \"Jean-Francois\", \"Alex\"], \n    \"lname\":[\"Binette\", \"Binette\", pd.NA]})\n\n    Link records which agree on both the \"fname\" and \"lname\" fields.\n    >>> rule = Match(\"fname\", \"lname\")\n\n    Fit linkage rule to the data.\n    >>> _ = rule.fit(df)\n\n    Construct deduplicated dataframe, retaining only the first record in each cluster.\n    >>> _ = df.groupby(rule.groups).first()\n    \"\"\"\n\n    def __init__(self, *args):\n        \"\"\"\n        Parameters\n        ----------\n        args: list containing strings and/or LinkageRule objects.\n            The `Match` object represents the logical conjunction of the set of \n            rules given in the `args` parameter. \n        \"\"\"\n        self.rules = args\n        self._update_graph = False\n        self.n = None\n\n    def fit(self, df):\n        self._groups = _groups_from_rules(self.rules, df)\n        self._update_graph = True\n        self.n = df.shape[0]\n\n        return self\n\n    @property\n    def groups(self):\n        return self._groups\n\nOne more method is needed to complete the implementation of a LinkageRule, namely the graph property. This property returns a Graph object corresponding to the matching rule. The graph is built as follows. First, we construct an inverted index for the clustering. That is, we construct a dictionary associating to each cluster the nodes which it contains. Then, an edge list is obtained by linking all pairs of nodes which belong to the same cluster. Note that the pure Python implementation below if not efficient for large clusters. This is not a problem for now since we will generally avoid computing this graph.\n\n# Part of the definition of the `Match` class:\n    @property\n    def graph(self) -> Graph:\n        if self._update_graph:\n            # Inverted index\n            clust = pd.DataFrame({\"groups\": self.groups}\n                                 ).groupby(\"groups\").indices\n            self._graph = Graph(n=self.n)\n            self._graph.add_edges(itertools.chain.from_iterable(\n                itertools.combinations(c, 2) for c in clust.values()))\n            self._update_graph = False\n        return self._graph\n\nFinally, let’s implement the Any class. It’s purpose is to take the union (i.e. logical disjunction) of a set of rules. Just like for Match, we can choose to operate at the groups or graph level. Here we’ll work at the groups level for efficiency. That is, given a set of rules, Any will first compute their corresponding clusters before merging overlapping clusters.\nThere are quite a few different ways to efficiently merge clusters. Here we’ll merge clusters by computing a “path graph” representation, taking the union of these graphs, and then computing connected components. For a given clustering, say containing records a, b, and c, the “path graph” links records as a path a–b–c.\nFirst, we define the functions needed to compute path graphs:\n\ndef pairwise(iterable):\n    \"\"\"\n    Iterate over consecutive pairs:\n        s -> (s[0], s[1]), (s[1], s[2]), (s[2], s[3]), ...\n\n    Note\n    ----\n    Current implementation is from itertools' recipes list available at \n    https://docs.python.org/3/library/itertools.html\n    \"\"\"\n    a, b = itertools.tee(iterable)\n    next(b, None)\n    return zip(a, b)\n\n\ndef _path_graph(rule, df):\n    \"\"\"\n    Compute path graph corresponding to the rule's clustering: cluster elements \n    are connected as a path.\n\n    Parameters\n    ----------\n    rule: string or LinkageRule\n        Linkage rule for which to compute the corresponding path graph \n        (strings are interpreted as exact matching rules for the corresponding column).\n    df: DataFrame\n        Data to which the linkage rule is fitted.\n\n    Returns\n    -------\n    Graph object such that nodes in the same cluster (according to the fitted \n    linkage rule) are connected as graph paths.\n    \"\"\"\n    gr = _groups(rule, df)\n    \n    # Inverted index\n    clust = pd.DataFrame({\"groups\": gr}\n                         ).groupby(\"groups\").indices\n    graph = Graph(n=df.shape[0])\n    graph.add_edges(itertools.chain.from_iterable(\n        pairwise(c) for c in clust.values()))\n\n    return graph\n\nWe can now implement the Any class:\n\nclass Any(LinkageRule):\n    \"\"\"\n    Class representing the logical disjunction of linkage rules.\n\n    Attributes\n    ----------\n    graph: igraph.Graph\n        Graph representing linkage fitted to the data. Defaults to None and is \n        instanciated after the `fit()` function is called.\n\n    groups: integer array\n        Membership vector for the linkage clusters fitted to the data. Defaults \n        to None and is instanciated after the `fit()` function is called.\n\n    Methods\n    -------\n    fit(df)\n        Fits linkage rule to the given dataframe.\n    \"\"\"\n\n    def __init__(self, *args):\n        \"\"\"\n        Parameters\n        ----------\n        args: list containing strings and/or LinkageRule objects.\n            The `Any` object represents the logical disjunction of the set of \n            rules given by `args`. \n        \"\"\"\n        self.rules = args\n        self._graph = None\n        self._groups = None\n        self._update_groups = False\n\n    def fit(self, df):\n        self._update_groups = True\n        graphs_vect = [_path_graph(rule, df) for rule in self.rules]\n        self._graph = igraph.union(graphs_vect)\n        return self\n\n    @property\n    def groups(self):\n        if self._update_groups:\n            self._update_groups = False\n            self._groups = np.array(\n                self._graph.clusters().membership)\n        return self._groups\n\n    @property\n    def graph(self) -> Graph:\n        return self._graph\n\nThe complete Python module (still under development) implementing this approach can be found on Github at OlivierBinette/GroupByRule.\nModel Evaluation\nUnfortunately, I cannot share the pantry data… but I can describe the model evaluation procedure.\nPrecision and recall\nHow do you estimate precision and recall?\nPrecision: easy, simply go through predicted clusters (or sample predicted clusters)\nRecall: try to find matches that we not correctly predicted. This can be done using probabilistic record linkage models that make use of additional information and sampling highest probability of matches among non-predicted pairs.\nNow, why not use probabilistic record linkage from the get go? Two reasons:\nDeterministic record linkage is more easily intelligible and justifiable using prior knowledge regarding the data structure.\nDeterministic record linkage can more easily be validated, using PRL as a tool to this end. If there is not much difference between the performance of deterministic record linkage and PRL, this indicates that the deterministic approach is likely to be sufficiently accurate in practice.\n\nFinal thoughts\nA future for black box entity resolution?\nEntity resolution is often an underspecified problem - different approaches can lead to very different answers and we need assumptions, or an understanding of the data-generating mechanism, to make it tractable.\nThis makes it important to develop a practice of record linkage, such as standards for its use, validation, and evaluation, which goes beyond the suggestion of generic methodology. This practice should be rooted in the simplicity of effective methods combined with the support of more sophisticated methods, rather than only the use of black-box methods which can overstate their accuracy.\n\n\n\n\n",
    "preview": "http://dukegpsc.org/wp-content/uploads/2019/07/pantry.jpg",
    "last_modified": "2021-12-23T17:18:40-05:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome!",
    "description": "Welcome to the blog of ASA's Record Linkage Interest Group.",
    "author": [
      {
        "name": "Olivier Binette",
        "url": "https://olivierbinette.github.io"
      }
    ],
    "date": "2021-12-23",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": "posts/welcome/wave.png",
    "last_modified": "2021-12-23T17:28:18-05:00",
    "input_file": {}
  }
]
